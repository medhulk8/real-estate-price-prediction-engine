{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Estate Price Prediction Engine - Technical Challenge\n",
    "\n",
    "## Objective\n",
    "Build a production-ready ML model to predict property transaction prices (TRANS_VALUE) with high accuracy and explainability.\n",
    "\n",
    "## Approach Overview\n",
    "1. **EDA**: Understand data quality, distributions, and business patterns\n",
    "2. **Feature Engineering**: Create predictive features while avoiding data leakage\n",
    "3. **Model Development**: Train CatBoost with log-transformed target and MAE loss\n",
    "4. **Evaluation**: Assess performance across price ranges and property segments\n",
    "5. **Interpretability**: Use SHAP to explain predictions and generate business insights\n",
    "\n",
    "## Key Technical Decisions\n",
    "- **Model**: CatBoost (handles categorical features natively, robust to outliers)\n",
    "- **Target Transform**: log1p (handles skewed price distribution)\n",
    "- **Loss Function**: MAE (robust to outliers)\n",
    "- **Split Strategy**: Chronological 70/15/15 (prevents temporal leakage)\n",
    "- **Feature Strategy**: Train-only aggregates with unseen category handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# For reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../transactions-2025-03-21.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 2.1 Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET STRUCTURE\")\n",
    "print(\"=\" * 80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column data types and descriptions\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COLUMN ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "column_info = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Null Count': df.isnull().sum(),\n",
    "    'Null %': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Unique Values': df.nunique()\n",
    "})\n",
    "\n",
    "column_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date column to understand temporal range\n",
    "df['INSTANCE_DATE'] = pd.to_datetime(df['INSTANCE_DATE'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEMPORAL COVERAGE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Date Range: {df['INSTANCE_DATE'].min()} to {df['INSTANCE_DATE'].max()}\")\n",
    "print(f\"Time Span: {(df['INSTANCE_DATE'].max() - df['INSTANCE_DATE'].min()).days} days\")\n",
    "print(f\"\\nTransactions by Year:\")\n",
    "print(df['INSTANCE_DATE'].dt.year.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Missing Values and Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed missing value analysis\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Empty_Strings': (df == '').sum(),\n",
    "    'Empty_String_Percentage': ((df == '').sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "missing_analysis = missing_analysis[\n",
    "    (missing_analysis['Missing_Count'] > 0) | (missing_analysis['Empty_Strings'] > 0)\n",
    "].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MISSING VALUES & DATA QUALITY ISSUES\")\n",
    "print(\"=\" * 80)\n",
    "if len(missing_analysis) > 0:\n",
    "    display(missing_analysis)\n",
    "else:\n",
    "    print(\"No missing values found!\")\n",
    "\n",
    "# Check for empty strings in categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\n\\nEmpty string counts in categorical columns:\")\n",
    "for col in categorical_cols:\n",
    "    empty_count = (df[col] == '').sum()\n",
    "    if empty_count > 0:\n",
    "        print(f\"{col}: {empty_count} ({empty_count/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Target Variable Analysis (TRANS_VALUE)\n",
    "\n",
    "Understanding the distribution of our target variable is crucial for:\n",
    "- Choosing appropriate transformations\n",
    "- Identifying outliers\n",
    "- Setting realistic performance expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of TRANS_VALUE\n",
    "print(\"=\" * 80)\n",
    "print(\"TARGET VARIABLE (TRANS_VALUE) STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(df['TRANS_VALUE'].describe())\n",
    "print(f\"\\nSkewness: {df['TRANS_VALUE'].skew():.2f}\")\n",
    "print(f\"Kurtosis: {df['TRANS_VALUE'].kurtosis():.2f}\")\n",
    "\n",
    "# Check for invalid values\n",
    "invalid_prices = (df['TRANS_VALUE'] <= 0).sum()\n",
    "print(f\"\\nInvalid prices (<=0): {invalid_prices} ({invalid_prices/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TRANS_VALUE distribution - Raw vs Log-transformed\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Raw distribution\n",
    "axes[0, 0].hist(df['TRANS_VALUE'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('TRANS_VALUE Distribution (Raw)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Transaction Value')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['TRANS_VALUE'].median(), color='red', linestyle='--', label=f'Median: {df[\"TRANS_VALUE\"].median():,.0f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Log-transformed distribution\n",
    "axes[0, 1].hist(np.log1p(df['TRANS_VALUE']), bins=100, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('TRANS_VALUE Distribution (Log1p)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Log(Transaction Value + 1)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Boxplot - Raw\n",
    "axes[1, 0].boxplot(df['TRANS_VALUE'], vert=False)\n",
    "axes[1, 0].set_title('TRANS_VALUE Boxplot (Raw)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Transaction Value')\n",
    "\n",
    "# Boxplot - Log\n",
    "axes[1, 1].boxplot(np.log1p(df['TRANS_VALUE']), vert=False)\n",
    "axes[1, 1].set_title('TRANS_VALUE Boxplot (Log1p)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Log(Transaction Value + 1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä OBSERVATION: Compare the distributions above.\")\n",
    "print(\"   - Raw distribution is highly right-skewed (long tail of expensive properties)\")\n",
    "print(\"   - Log transformation normalizes the distribution, making it more suitable for modeling\")\n",
    "print(\"   - This justifies using log1p(TRANS_VALUE) as our target during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numerical columns\n",
    "numerical_cols = ['TRANS_VALUE', 'PROCEDURE_AREA', 'ACTUAL_AREA', 'ROOMS_EN', \n",
    "                  'PARKING', 'TOTAL_BUYER', 'TOTAL_SELLER']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NUMERICAL FEATURES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "df[numerical_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data quality issues in numerical columns\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NUMERICAL DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in ['ACTUAL_AREA', 'PROCEDURE_AREA']:\n",
    "    zero_or_negative = (df[col] <= 0).sum()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  - Zero or negative values: {zero_or_negative} ({zero_or_negative/len(df)*100:.2f}%)\")\n",
    "    print(f\"  - Min: {df[col].min()}, Max: {df[col].max()}\")\n",
    "    print(f\"  - Median: {df[col].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute price per sqft for analysis (NOT as a model feature to avoid leakage)\n",
    "# This helps us understand the data and identify potential outliers\n",
    "df['price_per_sqft_temp'] = df['TRANS_VALUE'] / df['ACTUAL_AREA'].replace(0, np.nan)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRICE PER SQFT ANALYSIS (for EDA only, NOT a model feature)\")\n",
    "print(\"=\" * 80)\n",
    "print(df['price_per_sqft_temp'].describe())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(df['price_per_sqft_temp'].dropna(), bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Price per Sqft Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Price per Sqft')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].boxplot(df['price_per_sqft_temp'].dropna(), vert=False)\n",
    "axes[1].set_title('Price per Sqft Boxplot', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Price per Sqft')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cardinality of categorical features\n",
    "categorical_cols = ['GROUP_EN', 'PROCEDURE_EN', 'IS_OFFPLAN_EN', 'IS_FREE_HOLD_EN',\n",
    "                   'USAGE_EN', 'AREA_EN', 'PROP_TYPE_EN', 'PROP_SB_TYPE_EN',\n",
    "                   'NEAREST_METRO_EN', 'NEAREST_MALL_EN', 'NEAREST_LANDMARK_EN',\n",
    "                   'MASTER_PROJECT_EN', 'PROJECT_EN']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CATEGORICAL FEATURES CARDINALITY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cardinality_df = pd.DataFrame({\n",
    "    'Column': categorical_cols,\n",
    "    'Unique_Values': [df[col].nunique() for col in categorical_cols],\n",
    "    'Cardinality_Ratio': [df[col].nunique() / len(df) for col in categorical_cols]\n",
    "}).sort_values('Unique_Values', ascending=False)\n",
    "\n",
    "cardinality_df['Cardinality_Type'] = cardinality_df['Unique_Values'].apply(\n",
    "    lambda x: 'Low (<10)' if x < 10 else ('Medium (10-100)' if x < 100 else 'High (100+)')\n",
    ")\n",
    "\n",
    "display(cardinality_df)\n",
    "\n",
    "print(\"\\nüìä OBSERVATION:\")\n",
    "print(\"   - High cardinality features (PROJECT_EN, AREA_EN, etc.) need special handling\")\n",
    "print(\"   - CatBoost can handle these natively without one-hot encoding\")\n",
    "print(\"   - We'll create aggregated features from these for additional predictive power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top categories for selected features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# PROP_TYPE_EN\n",
    "top_prop_types = df['PROP_TYPE_EN'].value_counts().head(10)\n",
    "axes[0, 0].barh(range(len(top_prop_types)), top_prop_types.values)\n",
    "axes[0, 0].set_yticks(range(len(top_prop_types)))\n",
    "axes[0, 0].set_yticklabels(top_prop_types.index)\n",
    "axes[0, 0].set_title('Top 10 Property Types', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Count')\n",
    "\n",
    "# AREA_EN\n",
    "top_areas = df['AREA_EN'].value_counts().head(10)\n",
    "axes[0, 1].barh(range(len(top_areas)), top_areas.values)\n",
    "axes[0, 1].set_yticks(range(len(top_areas)))\n",
    "axes[0, 1].set_yticklabels(top_areas.index)\n",
    "axes[0, 1].set_title('Top 10 Areas', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Count')\n",
    "\n",
    "# IS_OFFPLAN_EN\n",
    "offplan_counts = df['IS_OFFPLAN_EN'].value_counts()\n",
    "axes[1, 0].bar(range(len(offplan_counts)), offplan_counts.values)\n",
    "axes[1, 0].set_xticks(range(len(offplan_counts)))\n",
    "axes[1, 0].set_xticklabels(offplan_counts.index)\n",
    "axes[1, 0].set_title('Off-Plan vs Ready Properties', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "\n",
    "# IS_FREE_HOLD_EN\n",
    "freehold_counts = df['IS_FREE_HOLD_EN'].value_counts()\n",
    "axes[1, 1].bar(range(len(freehold_counts)), freehold_counts.values)\n",
    "axes[1, 1].set_xticks(range(len(freehold_counts)))\n",
    "axes[1, 1].set_xticklabels(freehold_counts.index)\n",
    "axes[1, 1].set_title('Freehold vs Leasehold Properties', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 PROCEDURE_EN Analysis (Critical for Filtering Decision)\n",
    "\n",
    "**Why this matters:** The challenge asks us to predict market prices, but the dataset contains various transaction types (Sales, Mortgages, Gifts, etc.). We need to determine if non-sale transactions should be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze PROCEDURE_EN distribution\n",
    "print(\"=\" * 80)\n",
    "print(\"PROCEDURE_EN (Transaction Type) ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "procedure_counts = df['PROCEDURE_EN'].value_counts()\n",
    "print(\"\\nTransaction Type Distribution:\")\n",
    "print(procedure_counts)\n",
    "print(f\"\\nTotal unique procedure types: {df['PROCEDURE_EN'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze TRANS_VALUE by PROCEDURE_EN\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRANS_VALUE STATISTICS BY PROCEDURE_EN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "procedure_price_stats = df.groupby('PROCEDURE_EN')['TRANS_VALUE'].agg([\n",
    "    'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "]).sort_values('count', ascending=False)\n",
    "\n",
    "display(procedure_price_stats)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Count by procedure\n",
    "top_procedures = procedure_counts.head(10)\n",
    "axes[0].barh(range(len(top_procedures)), top_procedures.values)\n",
    "axes[0].set_yticks(range(len(top_procedures)))\n",
    "axes[0].set_yticklabels(top_procedures.index)\n",
    "axes[0].set_title('Top 10 Transaction Types by Count', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Count')\n",
    "\n",
    "# Median price by procedure (top 10 by count)\n",
    "top_procedure_names = top_procedures.index\n",
    "median_prices = df[df['PROCEDURE_EN'].isin(top_procedure_names)].groupby('PROCEDURE_EN')['TRANS_VALUE'].median()\n",
    "median_prices = median_prices.reindex(top_procedure_names)\n",
    "axes[1].barh(range(len(median_prices)), median_prices.values, color='green')\n",
    "axes[1].set_yticks(range(len(median_prices)))\n",
    "axes[1].set_yticklabels(median_prices.index)\n",
    "axes[1].set_title('Median Transaction Value by Type', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Median Transaction Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä DECISION POINT:\")\n",
    "print(\"   Based on the analysis above, we need to decide:\")\n",
    "print(\"   - Should we filter to only 'Sale' transactions?\")\n",
    "print(\"   - Or do multiple procedure types represent valid market prices?\")\n",
    "print(\"   - Look for procedure types with similar median prices to Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Outlier Detection and Handling Strategy\n",
    "\n",
    "**Approach:** Conservative, domain-driven outlier removal\n",
    "- Remove only obvious data errors (impossible values)\n",
    "- Keep legitimate luxury properties\n",
    "- Use robust loss (MAE) to reduce sensitivity to remaining outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential outliers based on domain rules\n",
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER DETECTION (Domain-Driven Rules)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Rule 1: Invalid areas (<=0)\n",
    "invalid_actual_area = (df['ACTUAL_AREA'] <= 0).sum()\n",
    "invalid_procedure_area = (df['PROCEDURE_AREA'] <= 0).sum()\n",
    "print(f\"\\nRule 1 - Invalid Areas:\")\n",
    "print(f\"  ACTUAL_AREA <= 0: {invalid_actual_area} rows ({invalid_actual_area/len(df)*100:.2f}%)\")\n",
    "print(f\"  PROCEDURE_AREA <= 0: {invalid_procedure_area} rows ({invalid_procedure_area/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Rule 2: Invalid transaction values (<=0)\n",
    "invalid_trans_value = (df['TRANS_VALUE'] <= 0).sum()\n",
    "print(f\"\\nRule 2 - Invalid Transaction Values:\")\n",
    "print(f\"  TRANS_VALUE <= 0: {invalid_trans_value} rows ({invalid_trans_value/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Rule 3: Extreme area values (will define thresholds based on percentiles)\n",
    "area_p01 = df['ACTUAL_AREA'].quantile(0.001)\n",
    "area_p99 = df['ACTUAL_AREA'].quantile(0.999)\n",
    "print(f\"\\nRule 3 - Extreme Area Values:\")\n",
    "print(f\"  0.1th percentile: {area_p01:.2f}\")\n",
    "print(f\"  99.9th percentile: {area_p99:.2f}\")\n",
    "extreme_small_area = (df['ACTUAL_AREA'] < area_p01).sum()\n",
    "extreme_large_area = (df['ACTUAL_AREA'] > area_p99).sum()\n",
    "print(f\"  Areas < {area_p01:.2f}: {extreme_small_area} rows\")\n",
    "print(f\"  Areas > {area_p99:.2f}: {extreme_large_area} rows\")\n",
    "\n",
    "# Rule 4: Extreme price-per-area ratios\n",
    "price_per_area_p01 = df['price_per_sqft_temp'].quantile(0.001)\n",
    "price_per_area_p99 = df['price_per_sqft_temp'].quantile(0.999)\n",
    "print(f\"\\nRule 4 - Extreme Price-per-Sqft Ratios:\")\n",
    "print(f\"  0.1th percentile: {price_per_area_p01:.2f}\")\n",
    "print(f\"  99.9th percentile: {price_per_area_p99:.2f}\")\n",
    "extreme_low_price_ratio = (df['price_per_sqft_temp'] < price_per_area_p01).sum()\n",
    "extreme_high_price_ratio = (df['price_per_sqft_temp'] > price_per_area_p99).sum()\n",
    "print(f\"  Price/sqft < {price_per_area_p01:.2f}: {extreme_low_price_ratio} rows\")\n",
    "print(f\"  Price/sqft > {price_per_area_p99:.2f}: {extreme_high_price_ratio} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Key Business Insights\n",
    "\n",
    "This section addresses the challenge requirements for insights on:\n",
    "- Price trends by property type, area, and time\n",
    "- Impact of location features\n",
    "- Off-plan vs ready property pricing\n",
    "- Freehold vs leasehold impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8.1 Price Trends by Property Type\n",
    "print(\"=\" * 80)\n",
    "print(\"PRICE TRENDS BY PROPERTY TYPE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "prop_type_stats = df.groupby('PROP_TYPE_EN').agg({\n",
    "    'TRANS_VALUE': ['count', 'mean', 'median'],\n",
    "    'ACTUAL_AREA': 'median'\n",
    "}).round(2)\n",
    "\n",
    "prop_type_stats.columns = ['Count', 'Mean_Price', 'Median_Price', 'Median_Area']\n",
    "prop_type_stats = prop_type_stats.sort_values('Count', ascending=False).head(10)\n",
    "\n",
    "display(prop_type_stats)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].barh(range(len(prop_type_stats)), prop_type_stats['Median_Price'])\n",
    "axes[0].set_yticks(range(len(prop_type_stats)))\n",
    "axes[0].set_yticklabels(prop_type_stats.index)\n",
    "axes[0].set_title('Median Price by Property Type (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Median Transaction Value')\n",
    "\n",
    "axes[1].barh(range(len(prop_type_stats)), prop_type_stats['Median_Area'], color='green')\n",
    "axes[1].set_yticks(range(len(prop_type_stats)))\n",
    "axes[1].set_yticklabels(prop_type_stats.index)\n",
    "axes[1].set_title('Median Area by Property Type (Top 10)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Median Area')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8.2 Price Trends by Area\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRICE TRENDS BY AREA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "area_stats = df.groupby('AREA_EN').agg({\n",
    "    'TRANS_VALUE': ['count', 'mean', 'median'],\n",
    "    'ACTUAL_AREA': 'median'\n",
    "}).round(2)\n",
    "\n",
    "area_stats.columns = ['Count', 'Mean_Price', 'Median_Price', 'Median_Area']\n",
    "area_stats = area_stats[area_stats['Count'] >= 50].sort_values('Median_Price', ascending=False).head(15)\n",
    "\n",
    "display(area_stats)\n",
    "\n",
    "# Visualize top premium areas\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.barh(range(len(area_stats)), area_stats['Median_Price'])\n",
    "plt.yticks(range(len(area_stats)), area_stats.index)\n",
    "plt.title('Top 15 Premium Areas by Median Price (min 50 transactions)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Median Transaction Value')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä INSIGHT: Location premium is significant - top areas command much higher prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8.3 Price Trends Over Time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRICE TRENDS OVER TIME\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Monthly median prices\n",
    "df['year_month'] = df['INSTANCE_DATE'].dt.to_period('M')\n",
    "monthly_prices = df.groupby('year_month')['TRANS_VALUE'].agg(['median', 'count'])\n",
    "\n",
    "# Quarterly median prices\n",
    "df['year_quarter'] = df['INSTANCE_DATE'].dt.to_period('Q')\n",
    "quarterly_prices = df.groupby('year_quarter')['TRANS_VALUE'].agg(['median', 'count'])\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Monthly trend\n",
    "axes[0].plot(monthly_prices.index.astype(str), monthly_prices['median'], marker='o', linewidth=2)\n",
    "axes[0].set_title('Median Transaction Price - Monthly Trend', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Median Price')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Quarterly trend\n",
    "axes[1].plot(quarterly_prices.index.astype(str), quarterly_prices['median'], marker='s', linewidth=2, color='green')\n",
    "axes[1].set_title('Median Transaction Price - Quarterly Trend', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Quarter')\n",
    "axes[1].set_ylabel('Median Price')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä INSIGHT: Temporal patterns visible - justifies including time-based features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8.4 Off-Plan vs Ready Properties\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OFF-PLAN VS READY PROPERTIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "offplan_comparison = df.groupby('IS_OFFPLAN_EN')['TRANS_VALUE'].agg([\n",
    "    'count', 'mean', 'median', 'std'\n",
    "]).round(2)\n",
    "\n",
    "display(offplan_comparison)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "df.boxplot(column='TRANS_VALUE', by='IS_OFFPLAN_EN', ax=axes[0])\n",
    "axes[0].set_title('Transaction Value: Off-Plan vs Ready', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Property Status')\n",
    "axes[0].set_ylabel('Transaction Value')\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Bar plot of medians\n",
    "axes[1].bar(range(len(offplan_comparison)), offplan_comparison['median'])\n",
    "axes[1].set_xticks(range(len(offplan_comparison)))\n",
    "axes[1].set_xticklabels(offplan_comparison.index)\n",
    "axes[1].set_title('Median Price: Off-Plan vs Ready', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Median Transaction Value')\n",
    "\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "price_diff_pct = (offplan_comparison.loc['Off-Plan', 'median'] / offplan_comparison.loc['Ready', 'median'] - 1) * 100 if 'Ready' in offplan_comparison.index and 'Off-Plan' in offplan_comparison.index else 0\n",
    "print(f\"\\nüìä INSIGHT: Off-plan properties are {abs(price_diff_pct):.1f}% {'more' if price_diff_pct > 0 else 'less'} expensive than ready properties (median)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8.5 Freehold vs Leasehold Impact\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FREEHOLD VS LEASEHOLD PROPERTIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "freehold_comparison = df.groupby('IS_FREE_HOLD_EN')['TRANS_VALUE'].agg([\n",
    "    'count', 'mean', 'median', 'std'\n",
    "]).round(2)\n",
    "\n",
    "display(freehold_comparison)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "df.boxplot(column='TRANS_VALUE', by='IS_FREE_HOLD_EN', ax=axes[0])\n",
    "axes[0].set_title('Transaction Value: Freehold vs Leasehold', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Ownership Type')\n",
    "axes[0].set_ylabel('Transaction Value')\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Bar plot of medians\n",
    "axes[1].bar(range(len(freehold_comparison)), freehold_comparison['median'], color='green')\n",
    "axes[1].set_xticks(range(len(freehold_comparison)))\n",
    "axes[1].set_xticklabels(freehold_comparison.index)\n",
    "axes[1].set_title('Median Price: Freehold vs Leasehold', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Median Transaction Value')\n",
    "\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "price_diff_pct_fh = (freehold_comparison.loc['Free Hold', 'median'] / freehold_comparison.loc['Lease Hold', 'median'] - 1) * 100 if 'Lease Hold' in freehold_comparison.index and 'Free Hold' in freehold_comparison.index else 0\n",
    "print(f\"\\nüìä INSIGHT: Freehold properties are {abs(price_diff_pct_fh):.1f}% {'more' if price_diff_pct_fh > 0 else 'less'} expensive than leasehold properties (median)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Cleaning and Preparation\n",
    "\n",
    "Based on EDA insights, we'll now:\n",
    "1. Filter dataset based on PROCEDURE_EN analysis\n",
    "2. Remove obvious data errors (outliers)\n",
    "3. Prepare data for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original dataset size\n",
    "original_size = len(df)\n",
    "print(f\"Original dataset size: {original_size:,} rows\")\n",
    "\n",
    "# TODO: Based on PROCEDURE_EN analysis above, decide filtering strategy\n",
    "# For now, we'll create a placeholder that will be filled after EDA analysis\n",
    "# Example: df_clean = df[df['PROCEDURE_EN'] == 'Sales'].copy()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  DECISION REQUIRED: Review PROCEDURE_EN analysis above to determine filtering strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Status: EDA Framework Complete ‚úì\n",
    "\n",
    "**Next Steps:**\n",
    "1. Run this notebook and analyze results\n",
    "2. Make decisions on PROCEDURE_EN filtering\n",
    "3. Define exact outlier removal rules\n",
    "4. Proceed to feature engineering section\n",
    "\n",
    "**The notebook will continue with:**\n",
    "- Feature Engineering\n",
    "- Model Training\n",
    "- Evaluation & Error Analysis\n",
    "- SHAP Interpretability\n",
    "\n",
    "This will be added in the next iteration after we analyze the EDA results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
